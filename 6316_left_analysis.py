# -*- coding: utf-8 -*-
"""6316_left_analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wyND4fK52njAmG28TFVumEVzG97sNQV0

# Download BB full slice (in smaller png)
"""

from google.colab import drive

# Mount Google Drive
G_DRIVE_MOUNTPOINT = "/drive"
drive.mount(G_DRIVE_MOUNTPOINT)

import os
import requests
from bs4 import BeautifulSoup

# The base URL to the FTP directory
base_url = "https://ftp.bigbrainproject.org/bigbrain-ftp/BigBrainRelease.2015/MicroDraw/2048_DZI/B20_6316_TS01_Pyramid.tiff_files/17/"

# Directory to save downloaded files
output_directory = "/drive/MyDrive/BB_FULL_SLICE"

# Create output directory if it does not exist
if not os.path.exists(output_directory):
    os.makedirs(output_directory)

def get_file_links(url):
    """
    Get all file links from the given FTP directory URL.
    """
    response = requests.get(url)
    if response.status_code != 200:
        raise Exception(f"Failed to access {url}")

    soup = BeautifulSoup(response.text, 'html.parser')
    links = []
    for link in soup.find_all('a'):
        href = link.get('href')
        if href and not href.startswith('?') and not href.startswith('/'):
            links.append(href)
    return links

def download_file(url, output_path):
    """
    Download a file from the given URL to the specified output path.
    """
    response = requests.get(url, stream=True)
    if response.status_code == 200:
        with open(output_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)
        print(f"Downloaded: {output_path}")
    else:
        print(f"Failed to download: {url}")

file_links = get_file_links(base_url)

# Download each file
for file_name in file_links:
  file_url = base_url + file_name
  output_path = os.path.join(output_directory, file_name)
  download_file(file_url, output_path)

"""# Full BB  slice TIF"""

from google.colab import drive

# Mount Google Drive
G_DRIVE_MOUNTPOINT = "/drive"
drive.mount(G_DRIVE_MOUNTPOINT)

import tifffile

# Load the TIFF file
file_path = "/drive/MyDrive/BB_FULL_SLICE/B20_6316_TS01_Pyramid.tif"
with tifffile.TiffFile(file_path) as tif:
    # Access the first page (or any page by index)
    image = tif.pages[0].asarray()

# Print basic details
print("Image shape:", image.shape)

import tifffile
import matplotlib.pyplot as plt

# Load the TIFF file
file_path = "/drive/MyDrive/BB_FULL_SLICE/B20_1582_TS02_Pyramid.tif"
with tifffile.TiffFile(file_path) as tif:
    # Access the first page (or any page by index)
    image = tif.pages[0].asarray()

# Print basic details
print("Image shape:", image.shape)

normalized_image = (image - image.min()) / (image.max() - image.min())

# Calculate midpoints
height, width = image.shape
mid_h, mid_w = height // 2, width // 2

# Divide the image into four parts
top_left = image[:mid_h, :mid_w]
top_right = image[:mid_h, mid_w:]
bottom_left = image[mid_h:, :mid_w]
bottom_right = image[mid_h:, mid_w:]

# Choose one part to display (e.g., top left)
chosen_part = top_left

# Display the chosen part
plt.figure(figsize=(10, 10))
plt.imshow(chosen_part, cmap='gray')
plt.axis('off')
plt.title("Top Left Part")
plt.show()

import numpy as np

# Normalize the image to range [0, 1]
image = top_left
normalized_image = (image - image.min()) / (image.max() - image.min())

# If needed, scale to [0, 255] for display
normalized_image = (normalized_image * 255).astype(np.uint8)


import matplotlib.pyplot as plt


plt.subplot(1, 2, 2)
plt.imshow(normalized_image, cmap='gray')
plt.title("Corrected Image")
plt.axis('off')

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

# Display the image
plt.figure(figsize=(10, 10))
plt.imshow(image,cmap='gray')
plt.axis('off')
#plt.savefig("/drive/MyDrive/BB_FULL_SLICE/hr_test.png", dpi = 3000)

"""## pyrammidal"""

from google.colab import drive

# Mount Google Drive
G_DRIVE_MOUNTPOINT = "/drive"
drive.mount(G_DRIVE_MOUNTPOINT)

import tifffile

file_path = "/drive/MyDrive/BB_FULL_SLICE/B20_6316_TS01_Pyramid.tif"
with tifffile.TiffFile(file_path) as tif:
    for page_index, page in enumerate(tif.pages):
        print(f"Page {page_index} shape: {page.shape}")
        # Load a specific resolution
        if page_index == 0:  # Example: Load only the first resolution
            image_pyr = page.asarray()

"""# Centroids detection"""

# Get the vertical midpoint
mid_col = image.shape[1] // 2  # Divide the number of columns by 2

# Slice the image vertically
left_half = image[:, :mid_col]  # Left half (columns 0 to mid_col-1)
right_half = image[:, mid_col:]  # Right half (columns mid_col to end)

# Verify the results visually
plt.figure()
plt.title("Left Half")
plt.imshow(left_half, cmap='gray')
plt.axis('off')
plt.show()

plt.figure()
plt.title("Right Half")
plt.imshow(right_half, cmap='gray')
plt.axis('off')
plt.show()

import matplotlib.pyplot as plt



# Get the dividing column index
factor = 1.85
dividing_col = int(image.shape[1] / factor)  # 1.5 means 2/3 vs 1/3 division

# Slice the image
larger_part = image[:, :dividing_col]  # First 2/3 of the image
smaller_part = image[:, dividing_col:]  # Last 1/3 of the image

# Verify the results visually
plt.figure()
plt.title("Larger Part (2/3)")
plt.imshow(larger_part, cmap='gray')
plt.axis('off')
plt.show()

plt.figure()
plt.title("Smaller Part (1/3)")
plt.imshow(smaller_part, cmap='gray')
plt.axis('off')
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Simulate an example grayscale image for testing
if 'image' not in globals():
    image = np.random.randint(0, 256, (300, 600), dtype=np.uint8)  # Random 300x600 grayscale image

# Define the dimensions for the first rectangle
rectangle1_height = 40000  # Height of the first rectangle
rectangle1_width = 2000    # Width of the first rectangle

# Define the dimensions for the second rectangle
rectangle2_height = 30000   # Height of the second rectangle
rectangle2_width = 3400    # Width of the second rectangle

# Define the dimensions for the second rectangle
rectangle3_height = 22000   # Height of the second rectangle
rectangle3_width = 3500    # Width of the second rectangle


# Define the dimensions for the second rectangle
rectangle4_height = 10000   # Height of the second rectangle
rectangle4_width = 4000    # Width of the second rectangle

# Get the dividing column index
factor = 1.85
dividing_col = int(image.shape[1] / factor)

# Slice the image
larger_part = image[:, :dividing_col]  # First 2/3 of the image

# Add the first rectangle (white) to the top-right corner of the larger part
modified_larger_part = np.copy(larger_part)

# First rectangle placement
start_row1 = 0
start_col1 = max(0, larger_part.shape[1] - rectangle1_width)  # Top-right corner
end_row1 = min(rectangle1_height, larger_part.shape[0])
end_col1 = larger_part.shape[1]
modified_larger_part[start_row1:end_row1, start_col1:end_col1] = 255

# Add the second rectangle (white) to the left of the first rectangle
start_row2 = 0
start_col2 = max(0, start_col1 - rectangle2_width)  # Left of the first rectangle
end_row2 = min(rectangle2_height, larger_part.shape[0])
end_col2 = start_col1
modified_larger_part[start_row2:end_row2, start_col2:end_col2] = 255

# Add the third rectangle (white) to the left of the first rectangle
start_row3 = 0
start_col3 = max(0, start_col2 - rectangle3_width)  # Left of the first rectangle
end_row2 = min(rectangle3_height, larger_part.shape[0])
end_col3 = start_col2
modified_larger_part[start_row2:end_row2, start_col3:end_col3] = 255

# Add the forutg rectangle (white) to the left of the first rectangle
start_row4 = 0
start_col4 = max(0, start_col3 - rectangle4_width)  # Left of the first rectangle
end_row4 = min(rectangle4_height, larger_part.shape[0])
end_col4 = start_col3
modified_larger_part[start_row3:end_row4, start_col4:end_col3] = 255

# Verify the results visually
plt.figure()
plt.imshow(modified_larger_part, cmap='gray')
plt.axis('off')
plt.show()

modified_larger_part.shape
file_path = "/drive/MyDrive/BB_FULL_SLICE/clean_right_slice.npy"
np.save(file_path, modified_larger_part)

"""# NOV 26"""

import numpy as np

from google.colab import drive

# Mount Google Drive
G_DRIVE_MOUNTPOINT = "/drive"
drive.mount(G_DRIVE_MOUNTPOINT)

im = np.load("/drive/MyDrive/BB_FULL_SLICE/6316_clean_left_slice.npy")
print(im.shape)

from scipy.ndimage import zoom

upsampled_im = zoom(im, 2, order=1)
print(upsampled_im.shape)

# Save the upsampled image as a .npy file
np.save("/drive/MyDrive/BB_FULL_SLICE/6316_cleanUPSAMPLED_left_slice.npy", upsampled_im)

print("Upsampled image saved as 'upsampled_image.npy'")

import numpy as np
from google.colab import drive

# Mount Google Drive
G_DRIVE_MOUNTPOINT = "/drive"
drive.mount(G_DRIVE_MOUNTPOINT)

im = np.load("/drive/MyDrive/BB_FULL_SLICE/6316_cleanUPSAMPLED_left_slice.npy")

im.shape

"""## Centroid detection"""

!pip install cucim

##### GPU


import cupy as cp
import cucim.skimage as skimage
from cucim.skimage.feature import peak_local_max
from cucim.skimage.filters import threshold_otsu
from cucim.skimage.morphology import remove_small_objects
import math
from tqdm import tqdm
from cupyx.scipy.ndimage import convolve



def getPts_gpu(imaniso, min_neuron=1, otsu_corr=0.75, max_neuron_brightness=125):
    mask = imaniso < cp.minimum(max_neuron_brightness, threshold_otsu(imaniso) * otsu_corr)
    mask = remove_small_objects(mask, min_size=min_neuron, connectivity=1)

    coordinates = peak_local_max(imaniso.max() - imaniso, min_distance=int(cp.ceil(cp.sqrt(min_neuron / 3.14))))

    # Convert coordinates to integers for valid indexing
    coordinates = cp.array(coordinates, dtype=int)

    # Filter coordinates using the mask
    valid_indices = [mask[tuple(coord.get())] for coord in coordinates]  # Convert each coord to NumPy for tuple indexing
    valid_indices = cp.array(valid_indices, dtype=bool)  # Ensure boolean CuPy array

    return coordinates[valid_indices]



def anisodiff_gpu(im, niter=12, delta=1.0 / 7.0, kappa=11, shRes=0):
    im = cp.array(im, dtype=cp.float64)  # Ensure CuPy array
    u = im

    masks = [
        cp.array([[0, 1, 0], [0, -1, 0], [0, 0, 0]], dtype=cp.float64),
        cp.array([[0, 0, 0], [0, -1, 0], [0, 1, 0]], dtype=cp.float64),
        cp.array([[0, 0, 0], [0, -1, 1], [0, 0, 0]], dtype=cp.float64),
        cp.array([[0, 0, 0], [1, -1, 0], [0, 0, 0]], dtype=cp.float64),
        cp.array([[0, 0, 1], [0, -1, 0], [0, 0, 0]], dtype=cp.float64),
        cp.array([[0, 0, 0], [0, -1, 0], [0, 0, 1]], dtype=cp.float64),
        cp.array([[0, 0, 0], [0, -1, 0], [1, 0, 0]], dtype=cp.float64),
        cp.array([[1, 0, 0], [0, -1, 0], [0, 0, 0]], dtype=cp.float64),
    ]

    for r in range(niter):
        PM = sum([
            cp.multiply(
                cp.exp(-cp.square(convolve(u, m) / kappa)),
                convolve(u, m)
            )
            for m in masks[:4]
        ]) + (1.0 / 2.0) * sum([
            cp.multiply(
                cp.exp(-cp.square(convolve(u, m) / kappa)),
                convolve(u, m)
            )
            for m in masks[4:]
        ])

        u = u + delta * PM

    return u  # CuPy array remains for GPU-based processing




def process_crop_gpu(im, top_left, full_shape):
    im = cp.array(im)  # Ensure CuPy array
    im_aniso = anisodiff_gpu(im, niter=12, delta=1.0 / 7.0, kappa=11, shRes=0)
    pts = getPts_gpu(im_aniso, min_neuron=1, otsu_corr=0.65, max_neuron_brightness=85)

    # Convert points back to NumPy for compatibility
    pts = cp.array(pts).get()
    pts[:, 0] += top_left[0]
    pts[:, 1] += top_left[1]
    pts = pts[(pts[:, 0] < full_shape[0]) & (pts[:, 1] < full_shape[1])]
    return pts


def crop_with_padding_gpu(image, crop_size=(100, 100), overlap=0.2):
    image = cp.array(image)  # Ensure CuPy array
    all_points = []
    h, w = image.shape[:2]
    stride_y, stride_x = int(crop_size[0] * (1 - overlap)), int(crop_size[1] * (1 - overlap))

    total_crops = ((h + stride_y - 1) // stride_y) * ((w + stride_x - 1) // stride_x)

    with tqdm(total=total_crops, desc="Processing Crops") as pbar:
        for y in range(0, h, stride_y):
            for x in range(0, w, stride_x):
                crop = image[y:y + crop_size[0], x:x + crop_size[1]]
                if crop.shape[0] != crop_size[0] or crop.shape[1] != crop_size[1]:
                    pad_y = max(0, crop_size[0] - crop.shape[0])
                    pad_x = max(0, crop_size[1] - crop.shape[1])
                    crop = cp.pad(crop, ((0, pad_y), (0, pad_x)), mode='reflect')

                points = process_crop_gpu(crop, (y, x), (h, w))
                all_points.extend(points)

                pbar.update(1)

    return cp.array(all_points).get()

# Run the crop and process function to get all points
#MIN NEURON = 1
all_points = crop_with_padding_gpu(im, crop_size=(100, 100), overlap=0.2)

# Run the crop and process function to get all points
#MIN NEURON = 1
all_points = crop_with_padding_gpu(im, crop_size=(100, 100), overlap=0.2)

print(f"detected cells: {len(all_points)}")
np.save("/drive/MyDrive/BB_FULL_SLICE/6316UPSAMPLED_centroids(MIN_NEURON1)_clean_left_slice.npy", all_points)

import matplotlib.pyplot as plt


im = np.load("/drive/MyDrive/BB_FULL_SLICE/clean_left_slice.npy")  #half right BB slice
print(im.shape)

all_points = np.load("/drive/MyDrive/BB_FULL_SLICE/centroids(MIN_NEURON10)_clean_left_slice.npy")
all_points = all_points.astype(int)
print(f"Centroids: {len(all_points)}")

# Plot the full image with all detected points
plt.figure(figsize=(20, 20))
plt.imshow(im, cmap='gray')
plt.plot(all_points[:, 1], all_points[:, 0], 'r.', markersize=0.1)
plt.axis("off")
plt.tight_layout()
plt.savefig("/drive/MyDrive/BB_FULL_SLICE/centroids(MIN_NEURON10)_clean_left_slice.png", dpi=2000, bbox_inches='tight', pad_inches=0)
plt.show()

"""## Segmentation

## Run anisoffdiff in whole slice by tiles
"""

import numpy as np
from scipy import ndimage
from tqdm import tqdm
from google.colab import drive

def anisodiff_tile(im_tile, niter=12, delta=1.0/7.0, kappa=11):
    """Applies anisotropic diffusion to a single tile."""
    im_tile = im_tile.astype('float64')
    u = im_tile.copy()

    hN = np.array([[0, 1, 0],
                   [0, -1, 0],
                   [0, 0, 0]], np.float64)  # N
    hS = np.array([[0, 0, 0],
                   [0, -1, 0],
                   [0, 1, 0]], np.float64)  # S
    hE = np.array([[0, 0, 0],
                   [0, -1, 1],
                   [0, 0, 0]], np.float64)  # E
    hW = np.array([[0, 0, 0],
                   [1, -1, 0],
                   [0, 0, 0]], np.float64)  # W
    hNE = np.array([[0, 0, 1],
                    [0, -1, 0],
                    [0, 0, 0]], np.float64)  # NE
    hSE = np.array([[0, 0, 0],
                    [0, -1, 0],
                    [0, 0, 1]], np.float64)  # SE
    hSW = np.array([[0, 0, 0],
                    [0, -1, 0],
                    [1, 0, 0]], np.float64)  # SW
    hNW = np.array([[1, 0, 0],
                    [0, -1, 0],
                    [0, 0, 0]], np.float64)  # NW

    masks = [hN, hS, hE, hW, hNE, hSE, hSW, hNW]
    weights = np.array([1, 1, 1, 1, 0.5, 0.5, 0.5, 0.5])

    for r in range(niter):
        PM = np.zeros_like(u)
        for m, w in zip(masks, weights):
            cu = ndimage.convolve(u, m, mode='nearest')
            c = np.exp(-np.square(cu / kappa))
            flux = c * cu
            PM += w * flux

        u += delta * PM

    return u

def process_image_in_tiles(im, tile_size, niter=12, delta=1.0/7.0, kappa=11):
    """Processes the image in smaller tiles with a progress bar."""
    h, w = im.shape
    processed_image = np.zeros_like(im, dtype='float64')

    # Total number of tiles
    total_tiles = (h // tile_size + (h % tile_size > 0)) * (w // tile_size + (w % tile_size > 0))

    with tqdm(total=total_tiles, desc="Processing tiles") as pbar:
        for i in range(0, h, tile_size):
            for j in range(0, w, tile_size):
                # Define the tile boundaries
                i_end = min(i + tile_size, h)
                j_end = min(j + tile_size, w)
                tile = im[i:i_end, j:j_end]

                # Apply anisotropic diffusion to the tile
                processed_tile = anisodiff_tile(tile, niter, delta, kappa)
                processed_image[i:i_end, j:j_end] = processed_tile

                # Update the progress bar
                pbar.update(1)

    return processed_image

# Mount Google Drive
G_DRIVE_MOUNTPOINT = "/drive"
drive.mount(G_DRIVE_MOUNTPOINT)

# Load the image
im = np.load("/drive/MyDrive/BB_FULL_SLICE/clean_right_slice.npy")

# Process the image in smaller tiles
tile_size = 1024  # Adjust this size based on memory capacity
im_aniso = process_image_in_tiles(im, tile_size)

# Save the processed image
np.save("/drive/MyDrive/BB_FULL_SLICE/anisodiff_clean_right_slice.npy", im_aniso)

"""## Segmentation method"""

def getCellAreas_enhanced_gpu(imaniso, init_locs, min_neuron=50, otsu_corr=1.0, timing=False):
    import time
    import cupy as cp
    from cupyx.scipy.ndimage import grey_erosion
    from skimage.filters import threshold_otsu
    from skimage.morphology import square
    # Convert the input image to a CuPy array for GPU computation
    imaniso_gpu = cp.asarray(imaniso, dtype=cp.float32)
    nx, ny = imaniso_gpu.shape
    N = nx * ny

    if timing:
        start_time = time.time()

    # Pad the image to handle edges
    padded_image = cp.pad(imaniso_gpu, pad_width=1, mode='edge')

    # Offsets corresponding to the 8 neighbors (excluding the center)
    offsets = [(-1, -1), (-1, 0), (-1, 1),
               (0, -1),          (0, 1),
               (1, -1),  (1, 0),  (1, 1)]
    offsets_array = cp.array(offsets, dtype=cp.int8)  # Shape: (8, 2)

    # Initialize arrays to hold neighbor images
    neighbor_images = cp.empty((nx, ny, 8), dtype=cp.float32)

    # Extract the center pixels
    center = padded_image[1:-1, 1:-1]

    # Populate neighbor_images
    for idx, (dy, dx) in enumerate(offsets):
        neighbor = padded_image[1 + dy : nx + 1 + dy, 1 + dx : ny + 1 + dx]
        neighbor_images[:, :, idx] = neighbor

    # Find minimal neighbor values and their indices
    min_neighbor_values = neighbor_images.min(axis=2)
    min_neighbor_indices = neighbor_images.argmin(axis=2)

    # Get the offsets corresponding to the minimal neighbors
    min_offsets = offsets_array[min_neighbor_indices]  # Shape: (nx, ny, 2)

    # Determine if the minimal neighbor has a value less than or equal to the center pixel
    move_mask = min_neighbor_values <= center

    # Determine if the minimal neighbor is not the center pixel (already ensured)
    has_lower_neighbor = move_mask

    # Set offsets to zero where we don't move
    min_offsets[~move_mask] = 0

    # Compute destination indices
    idx_i, idx_j = cp.meshgrid(cp.arange(nx), cp.arange(ny), indexing='ij')
    dest_i = idx_i + min_offsets[..., 0]
    dest_j = idx_j + min_offsets[..., 1]
    dest_indices = dest_i * ny + dest_j

    # Set dest_indices to -1 where we don't have a lower neighbor
    dest_indices_flat = cp.where(has_lower_neighbor.flatten(), dest_indices.flatten(), -1).astype(cp.int32)

    ptrs_flat = dest_indices_flat  # This replaces ptrs_flat

    if timing:
        print('Determine minimal neighbors: {:.1f}s'.format(time.time() - start_time))
        start_time = time.time()

    # Prepare initial labels
    roi = cp.zeros(N, dtype=cp.int32)
    locations1D = cp.array([x[0] * ny + x[1] for x in init_locs], dtype=cp.int32)
    roi[locations1D] = cp.arange(1, len(locations1D) + 1, dtype=cp.int32)

    if timing:
        print('Initialize basins: {:.1f}s'.format(time.time() - start_time))
        start_time = time.time()

    # Propagate labels
    labels = cp.copy(roi)
    max_iters = 1000  # Maximum iterations to prevent infinite loops

    for _ in range(max_iters):
        prev_labels = labels.copy()
        # For pixels with ptrs >= 0, inherit the label from the destination
        dest_labels = cp.where(ptrs_flat >= 0, labels[ptrs_flat], 0)
        labels = cp.where((labels == 0) & (ptrs_flat >= 0), dest_labels, labels)
        # Check for convergence
        if cp.all(labels == prev_labels):
            break

    roi = labels

    if timing:
        print('Propagate labels: {:.1f}s'.format(time.time() - start_time))
        start_time = time.time()

    # Build id_basins dictionary
    unique_labels = cp.unique(roi)
    id_basins = {}
    for label in unique_labels:
        if label > 0:
            indices = cp.where(roi == label)[0]
            id_basins[int(label)] = indices

    # Copy the image data to CPU for threshold computation
    imaniso_cpu = cp.asnumpy(imaniso_gpu)

    # Compute global Otsu threshold on CPU
    otsu_global = threshold_otsu(imaniso_cpu)

    thrld_components = {}

    for key in id_basins.keys():
        indices = id_basins[key]
        if len(indices) == 0:
            continue
        # Get the pixel values for the basin
        vals_gpu = imaniso_gpu.flatten()[indices]
        vals_cpu = cp.asnumpy(vals_gpu)
        # Compute local Otsu threshold on CPU
        otsu_t = min(threshold_otsu(vals_cpu), otsu_global) * otsu_corr
        # Identify pixels below the threshold
        component = indices[vals_gpu < otsu_t]
        if len(component) > min_neuron:
            thrld_components[key] = component

    # Apply morphological erosion
    from skimage.morphology import square
    selem = cp.asarray(square(3))
    for key in thrld_components.keys():
        mask = cp.zeros(N, dtype=cp.bool_)
        mask[thrld_components[key]] = True
        mask_2d = mask.reshape(nx, ny)
        eroded_mask = grey_erosion(mask_2d.astype(cp.uint8), footprint=selem)
        thrld_components[key] = cp.flatnonzero(eroded_mask.flatten())

    if timing:
        print('Threshold components and erosion: {:.1f}s'.format(time.time() - start_time))

    print(f"Segmented regions: {len(thrld_components)}")

    # Convert results back to CPU arrays if necessary
    thrld_components_cpu = {k: cp.asnumpy(v) for k, v in thrld_components.items()}

    return thrld_components_cpu

"""## Run segmentation"""

import numpy as np
from google.colab import drive

# Mount Google Drive
G_DRIVE_MOUNTPOINT = "/drive"
drive.mount(G_DRIVE_MOUNTPOINT)

im = np.load("/drive/MyDrive/BB_FULL_SLICE/clean_left_slice.npy")  #half left BB slice
print(im.shape)

pts = np.load("/drive/MyDrive/BB_FULL_SLICE/centroids(MIN_NEURON10)_clean_left_slice.npy")
pts = pts.astype(int)
print(f"Centroids: {len(pts)}")

im_aniso = np.load("/drive/MyDrive/BB_FULL_SLICE/anisodiff_clean_left_slice.npy")
print(im_aniso.shape)

#SEGMENTATION IN TILES

from tqdm import tqdm
import time

SEGMENT = True
if SEGMENT:

  # # # Define tile size and overlap
  tile_height, tile_width = 4000, 4000
  overlap = 200  # Adjust overlap based on object sizes
  height, width = im_aniso.shape

  # # Initialize a dictionary to store results
  cell_areas_all = {}

  start_time = time.time()

  # Calculate the total number of tiles for the progress bar
  num_tiles_y = (height - 1) // (tile_height - overlap) + 1
  num_tiles_x = (width - 1) // (tile_width - overlap) + 1
  total_tiles = num_tiles_y * num_tiles_x

  # Initialize the progress bar
  with tqdm(total=total_tiles, desc="Processing tiles") as pbar:
      # Loop over tiles
      label_offset = 0  # To ensure unique labels across tiles
      for i in range(0, height, tile_height - overlap):
          for j in range(0, width, tile_width - overlap):
              # Update progress bar
              pbar.update(1)

              # Define the tile boundaries with overlap
              i_start = max(i - overlap, 0)
              i_end = min(i + tile_height + overlap, height)
              j_start = max(j - overlap, 0)
              j_end = min(j + tile_width + overlap, width)

              # Extract the tile
              tile = im_aniso[i_start:i_end, j_start:j_end]

              # Extract and adjust seed points for this tile
              mask_pts = (pts[:, 0] >= i_start) & (pts[:, 0] < i_end) & \
                        (pts[:, 1] >= j_start) & (pts[:, 1] < j_end)
              tile_pts = pts[mask_pts]
              tile_pts_adjusted = tile_pts - np.array([i_start, j_start])

              if tile_pts_adjusted.size == 0:
                  # Optionally, print a message
                  # print(f"No seed points in tile at ({i_start}, {j_start}). Skipping.")
                  continue  # Skip tiles with no seed points

              # Run the segmentation on the tile
              try:
                  cell_areas_tile = getCellAreas_enhanced_gpu(
                      tile, tile_pts_adjusted, min_neuron=10, otsu_corr=0.9
                  )
                  # Uncomment to see the number of segments in each tile
                  # print(f"Segmented regions in tile at ({i_start}, {j_start}): {len(cell_areas_tile)}")
              except Exception as e:
                  print(f"Error processing tile at ({i_start}, {j_start}): {e}")
                  continue

              # Adjust indices back to global coordinates and store results
              for label, indices in cell_areas_tile.items():
                  # Ensure unique labels by adding an offset
                  global_label = label + label_offset

                  # Convert flat indices to 2D indices within the tile
                  tile_indices_i = indices // tile.shape[1]
                  tile_indices_j = indices % tile.shape[1]

                  # Adjust to global coordinates
                  global_indices_i = tile_indices_i + i_start
                  global_indices_j = tile_indices_j + j_start
                  global_indices = global_indices_i * width + global_indices_j

                  if global_label in cell_areas_all:
                      cell_areas_all[global_label].extend(global_indices.tolist())
                  else:
                      cell_areas_all[global_label] = global_indices.tolist()

              # Update label offset
              label_offset += len(cell_areas_tile)

  print(f"Total time taken: {time.time() - start_time:.2f} seconds")
  print(f"Segmented cell areas: {len(cell_areas_all)}")
  import pickle

  # Save cell_areas_all to a file
  with open('/drive/MyDrive/BB_FULL_SLICE/centroids(MIN_NEURON1)_clean_left_slice_cell_areas_all.pkl', 'wb') as f:
      pickle.dump(cell_areas_all, f, protocol=pickle.HIGHEST_PROTOCOL)

import pickle
import numpy as np
from google.colab import drive


# Mount Google Drive
G_DRIVE_MOUNTPOINT = "/drive"
drive.mount(G_DRIVE_MOUNTPOINT)

# # Load cell_areas_all from the file
with open('/drive/MyDrive/BB_FULL_SLICE/centroids_clean_left_slice_cell_areas_all.pkl', 'rb') as f:
     cell_areas_all = pickle.load(f)


im = np.load("/drive/MyDrive/BB_FULL_SLICE/clean_left_slice.npy")  #half left BB slice
print(im.shape)
im_aniso = im
height, width = im_aniso.shape

# Visualize the segmentation results
segmentation_mask = np.zeros(im_aniso.shape, dtype=np.int32)
for label, indices in cell_areas_all.items():
  indices = np.array(indices, dtype=np.int64)  # Ensure indices are integers
  indices_i = indices // im_aniso.shape[1]
  indices_j = indices % im_aniso.shape[1]
  segmentation_mask[indices_i, indices_j] = label

import numpy as np
import matplotlib.pyplot as plt

import pickle
import numpy as np
from google.colab import drive


# Mount Google Drive
G_DRIVE_MOUNTPOINT = "/drive"
drive.mount(G_DRIVE_MOUNTPOINT)

# # Load cell_areas_all from the file
with open('/drive/MyDrive/BB_FULL_SLICE/centroids_clean_right_slice_cell_areas_all.pkl', 'rb') as f:
     cell_areas_all = pickle.load(f)


im = np.load("/drive/MyDrive/BB_FULL_SLICE/clean_left_slice.npy")  #half left BB slice
print(im.shape)
im_aniso = im
height, width = im_aniso.shape

# Assuming 'height' and 'width' are defined as per your original image dimensions
segmentation_image = np.zeros((height, width), dtype=np.int32)

for label, indices in cell_areas_all.items():
    # Convert flat indices to 2D coordinates
    indices = np.array(indices, dtype=np.int64)
    indices_i = (indices // width).astype(np.int64)
    indices_j = (indices % width).astype(np.int64)
    # Assign the label to the segmentation image
    segmentation_image[indices_i, indices_j] = label

plt.figure(figsize=(10, 10))
plt.imshow(segmentation_image, cmap='nipy_spectral')
plt.colorbar()
plt.title('Segmented Cell Areas')
plt.axis('off')  # Hide the axes if desired
#plt.savefig("/drive/MyDrive/BB_FULL_SLICE/SEGMENTED_clean_right_slice.png", dpi=1500, bbox_inches='tight', pad_inches=0)
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Assuming 'segmentation_image' is already defined
plt.figure(figsize=(10, 10))

# Create a colormap where 0 values (background) are transparent
cmap = plt.cm.nipy_spectral
cmap.set_under(color='white', alpha=0)  # Set color for under the minimum threshold

# Plot the image
plt.imshow(segmentation_image, cmap=cmap, vmin=1)  # Set vmin to exclude 0 from the colormap
plt.colorbar()
plt.title('Segmented Cell Areas')
plt.axis('off')  # Hide the axes if desired

# Optionally save the modified figure
# plt.savefig("/path/to/save/segmented_image.png", dpi=1500, bbox_inches='tight', pad_inches=0)

plt.show()

import matplotlib.pyplot as plt

import numpy as np
import matplotlib.pyplot as plt

import pickle
import numpy as np
from google.colab import drive


# Mount Google Drive
G_DRIVE_MOUNTPOINT = "/drive"
drive.mount(G_DRIVE_MOUNTPOINT)

# # Load cell_areas_all from the file
with open('/drive/MyDrive/BB_FULL_SLICE/6316_centroids(MIN_NEURON1)_clean_left_slice_cell_areas_all.pkl', 'rb') as f:
     cell_areas_all = pickle.load(f)


im = np.load("/drive/MyDrive/BB_FULL_SLICE/6316_clean_left_slice.npy")  #half left BB slice
print(im.shape)
im_aniso = im
height, width = im_aniso.shape

# Assuming 'height' and 'width' are defined as per your original image dimensions
segmentation_image = np.zeros((height, width), dtype=np.int32)

for label, indices in cell_areas_all.items():
    # Convert flat indices to 2D coordinates
    indices = np.array(indices, dtype=np.int64)
    indices_i = (indices // width).astype(np.int64)
    indices_j = (indices % width).astype(np.int64)
    # Assign the label to the segmentation image
    segmentation_image[indices_i, indices_j] = label

plt.figure(figsize=(20, 20))
plt.imshow(im, cmap='gray')

cmap = plt.cm.nipy_spectral
cmap.set_under(color='white', alpha=0)  # Set color for under the minimum threshold
#plt.imshow(segmentation_image, cmap=cmap, vmin=1)  # Set vmin to exclude 0 from the colormap
plt.imshow(segmentation_image, cmap=cmap, vmin=1, interpolation='nearest')

# Plot the image
plt.axis("off")
plt.tight_layout()
plt.savefig("/drive/MyDrive/BB_FULL_SLICE/SEGMENTED(MIN_NEURON1)_clean_left_slice.png", dpi=2000, bbox_inches='tight', pad_inches=0)
plt.show()

"""## Save the combination of segmentation_image (mask) and im (original image) as an .npy file"""

import numpy as np
import matplotlib.pyplot as plt
import pickle
from google.colab import drive

# Mount Google Drive
G_DRIVE_MOUNTPOINT = "/drive"
drive.mount(G_DRIVE_MOUNTPOINT)

# Load cell_areas_all from the file
with open('/drive/MyDrive/BB_FULL_SLICE/6316_centroids(MIN_NEURON1)_clean_left_slice_cell_areas_all.pkl', 'rb') as f:
    cell_areas_all = pickle.load(f)

im = np.load("/drive/MyDrive/BB_FULL_SLICE/6316_clean_left_slice.npy")  #half left BB slice
print(im.shape)
im_aniso = im
height, width = im_aniso.shape

# Create the segmentation image
segmentation_image = np.zeros((height, width), dtype=np.int32)

for label, indices in cell_areas_all.items():
    # Convert flat indices to 2D coordinates
    indices = np.array(indices, dtype=np.int64)
    indices_i = (indices // width).astype(np.int64)
    indices_j = (indices % width).astype(np.int64)
    # Assign the label to the segmentation image
    segmentation_image[indices_i, indices_j] = label

# Combine original image and segmentation into a single array
combined_array = np.stack((im, segmentation_image), axis=-1)

# Save the combined array as an .npy file
output_path = "/drive/MyDrive/BB_FULL_SLICE/SEGMENTED(MIN_NEURON1)_clean_left_slice.npy"
np.save(output_path, combined_array)

print(f"Combined array saved as: {output_path}")

import numpy as np
import matplotlib.pyplot as plt

# Load the combined array
combined_array_path = "/drive/MyDrive/BB_FULL_SLICE/SEGMENTED(MIN_NEURON1)_clean_left_slice.npy"
combined_array = np.load(combined_array_path)

# Separate the original image and segmentation mask
original_image = combined_array[:, :, 0]
segmentation_mask = combined_array[:, :, 1]

# Overlay the segmentation mask on the original image
plt.figure(figsize=(10, 10))
plt.title("Combined Original Image and Segmentation Mask")

# Plot the original image in grayscale
plt.imshow(original_image, cmap='gray', interpolation='nearest')

# Overlay the segmentation mask
cmap = plt.cm.nipy_spectral
cmap.set_under(color='white', alpha=0)  # Exclude mask background
plt.imshow(segmentation_mask, cmap=cmap, vmin=1, alpha=0.5, interpolation='nearest')  # Adjust alpha for transparency

# Finalize the plot
plt.axis("off")
plt.tight_layout()
plt.show()

"""## Merged image"""

import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
import os
from google.colab import drive

# Mount Google Drive
G_DRIVE_MOUNTPOINT = "/drive"
drive.mount(G_DRIVE_MOUNTPOINT)

import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm

# Define paths for left and right segmented slices
left_slice_path = "/drive/MyDrive/BB_FULL_SLICE/SEGMENTED(MIN_NEURON1)_clean_left_slice.npy"
right_slice_path = "/drive/MyDrive/BB_FULL_SLICE/SEGMENTED(MIN_NEURON1)_clean_right_slice.npy"

# Function to process and load slices in chunks
def load_chunked_array(array_path, chunk_size):
    """
    Generator to load chunks of a large .npy array.
    """
    array = np.load(array_path, mmap_mode="r")
    total_slices = array.shape[0]
    for start in range(0, total_slices, chunk_size):
        end = min(start + chunk_size, total_slices)
        chunk = array[start:end]
        yield chunk, start, end

# Function to pad arrays to match dimensions
def pad_to_match(array1, array2, axis=1, padding_value=128):
    """
    Pads the smaller array along the specified axis to match the dimensions of the larger array.
    Allows setting the padding value to match the background color.
    """
    size1 = array1.shape[axis]
    size2 = array2.shape[axis]
    if size1 == size2:
        return array1, array2

    if size1 < size2:
        padding_shape = list(array1.shape)
        padding_shape[axis] = size2 - size1
        padding = np.full(padding_shape, padding_value, dtype=array1.dtype)
        array1 = np.concatenate((array1, padding), axis=axis)
    else:
        padding_shape = list(array2.shape)
        padding_shape[axis] = size1 - size2
        padding = np.full(padding_shape, padding_value, dtype=array2.dtype)
        array2 = np.concatenate((array2, padding), axis=axis)

    return array1, array2



def visualize_combined(left_array, right_array, start, end):
    """
    Visualize the left and right hemispheres in the same plot.
    """
    # Combine left and right horizontally
    combined_image = np.concatenate((left_array, right_array), axis=2)  # Combine along the width

    # Extract original and mask layers
    original_left = combined_image[:, :, 0]
    mask_left = combined_image[:, :, 1]
    original_right = combined_image[:, :, 2]
    mask_right = combined_image[:, :, 3]

    # Combine left and right for a single display
    combined_original = np.concatenate((original_left, original_right), axis=1)  # Combine horizontally
    combined_mask = np.concatenate((mask_left, mask_right), axis=1)  # Combine horizontally

    # Plot the combined image
    plt.figure(figsize=(15, 7))
    plt.imshow(combined_original, cmap='gray', interpolation='nearest')
    plt.imshow(combined_mask, cmap='nipy_spectral', alpha=0.5, interpolation='nearest')
    plt.title(f"Hemispheres Combined: Slices {start}-{end}")
    plt.axis("off")
    plt.tight_layout()
    plt.show()


# Set batch size for processing
chunk_size = 5000  # Adjust based on available memory

# Get the total number of slices for progress bar initialization
left_total_slices = np.load(left_slice_path, mmap_mode="r").shape[0]
right_total_slices = np.load(right_slice_path, mmap_mode="r").shape[0]

if left_total_slices != right_total_slices:
    raise ValueError("Left and right slice arrays must have the same number of slices!")

# Initialize the progress bar
with tqdm(total=left_total_slices, desc="Processing Slices", unit="slice") as pbar:
    # Process and visualize chunks
    for (left_chunk, left_start, left_end), (right_chunk, right_start, right_end) in zip(
        load_chunked_array(left_slice_path, chunk_size),
        load_chunked_array(right_slice_path, chunk_size)
    ):
        if left_start != right_start or left_end != right_end:
            raise ValueError("Mismatch between left and right slice ranges!")

        # Pad the arrays to match dimensions
        left_chunk, right_chunk = pad_to_match(left_chunk, right_chunk, axis=1)  # Adjust along width
        left_chunk, right_chunk = pad_to_match(left_chunk, right_chunk, axis=2)  # Adjust along height

        # Combine left and right arrays for visualization
        combined_chunk = np.concatenate((left_chunk, right_chunk), axis=-1)

        # Visualize the combined chunk
        visualize_combined(left_chunk, right_chunk, left_start, left_end)

        # Update the progress bar
        pbar.update(left_end - left_start)

import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
import os
from google.colab import drive

# Mount Google Drive
G_DRIVE_MOUNTPOINT = "/drive"
drive.mount(G_DRIVE_MOUNTPOINT)

# Define paths for left and right segmented slices
left_slice_path = "/drive/MyDrive/BB_FULL_SLICE/SEGMENTED(MIN_NEURON1)_clean_left_slice.npy"
right_slice_path = "/drive/MyDrive/BB_FULL_SLICE/SEGMENTED(MIN_NEURON1)_clean_right_slice.npy"

# Paths to save the final arrays
final_combined_original_path = "/drive/MyDrive/BB_FULL_SLICE/final_combined_original.npy"
final_combined_mask_path = "/drive/MyDrive/BB_FULL_SLICE/final_combined_mask.npy"

# Function to process and load slices in chunks
def load_chunked_array(array_path, chunk_size):
    """
    Generator to load chunks of a large .npy array.
    """
    array = np.load(array_path, mmap_mode="r")
    total_slices = array.shape[0]
    for start in range(0, total_slices, chunk_size):
        end = min(start + chunk_size, total_slices)
        chunk = array[start:end]
        yield chunk, start, end

# Function to pad arrays to match dimensions
def pad_to_match(array1, array2, axis=1, padding_value=128):
    """
    Pads the smaller array along the specified axis to match the dimensions of the larger array.
    """
    size1 = array1.shape[axis]
    size2 = array2.shape[axis]
    if size1 == size2:
        return array1, array2

    if size1 < size2:
        padding_shape = list(array1.shape)
        padding_shape[axis] = size2 - size1
        padding = np.full(padding_shape, padding_value, dtype=array1.dtype)
        array1 = np.concatenate((array1, padding), axis=axis)
    else:
        padding_shape = list(array2.shape)
        padding_shape[axis] = size1 - size2
        padding = np.full(padding_shape, padding_value, dtype=array2.dtype)
        array2 = np.concatenate((array2, padding), axis=axis)

    return array1, array2

# Set batch size for processing
chunk_size = 5000  # Adjust based on available memory

# Get the total number of slices
left_total_slices = np.load(left_slice_path, mmap_mode="r").shape[0]
right_total_slices = np.load(right_slice_path, mmap_mode="r").shape[0]

if left_total_slices != right_total_slices:
    raise ValueError("Left and right slice arrays must have the same number of slices!")

# Initialize the progress bar and the final image array
final_combined_original = []
final_combined_mask = []

with tqdm(total=left_total_slices, desc="Processing Slices", unit="slice") as pbar:
    # Process and combine chunks
    for (left_chunk, left_start, left_end), (right_chunk, right_start, right_end) in zip(
        load_chunked_array(left_slice_path, chunk_size),
        load_chunked_array(right_slice_path, chunk_size)
    ):
        if left_start != right_start or left_end != right_end:
            raise ValueError("Mismatch between left and right slice ranges!")

        # Pad the arrays to match dimensions
        left_chunk, right_chunk = pad_to_match(left_chunk, right_chunk, axis=1)
        left_chunk, right_chunk = pad_to_match(left_chunk, right_chunk, axis=2)

        # Combine the left and right chunks
        combined_image = np.concatenate((left_chunk, right_chunk), axis=2)

        # Extract and append original and mask layers
        original_left = combined_image[:, :, 0]
        mask_left = combined_image[:, :, 1]
        original_right = combined_image[:, :, 2]
        mask_right = combined_image[:, :, 3]

        combined_original = np.concatenate((original_left, original_right), axis=1)
        combined_mask = np.concatenate((mask_left, mask_right), axis=1)

        final_combined_original.append(combined_original)
        final_combined_mask.append(combined_mask)

        # Update the progress bar
        pbar.update(left_end - left_start)

# Combine all processed chunks into one final image
final_combined_original = np.vstack(final_combined_original)
final_combined_mask = np.vstack(final_combined_mask)

# Save the arrays to .npy files
np.save(final_combined_original_path, final_combined_original)
np.save(final_combined_mask_path, final_combined_mask)

# Print confirmation
print(f"Final combined original saved to: {final_combined_original_path}")
print(f"Final combined mask saved to: {final_combined_mask_path}")

import numpy as np
import matplotlib.pyplot as plt
from google.colab import drive

# Mount Google Drive
G_DRIVE_MOUNTPOINT = "/drive"
drive.mount(G_DRIVE_MOUNTPOINT)

# Path to the final_combined_mask.npy file
final_combined_mask_path = "/drive/MyDrive/BB_FULL_SLICE/final_combined_mask.npy"
final_combined_original_path = "/drive/MyDrive/BB_FULL_SLICE/final_combined_original.npy"

# Load the .npy file
final_combined_mask = np.load(final_combined_mask_path, mmap_mode='r')
final_combined_original= np.load(final_combined_original_path, mmap_mode='r')


# Check the shape of the loaded data
print(f"Shape of final_combined_mask: {final_combined_mask.shape}")
print(f"Shape of final_combined_original: {final_combined_original.shape}")

plt.figure(figsize=(10, 10))
#plt.title("Combined Original Image and Segmentation Mask")

# Plot the original image in grayscale
plt.imshow(final_combined_original, cmap='gray')

# Overlay the segmentation mask
cmap = plt.cm.nipy_spectral
cmap.set_under(color='white', alpha=0)  # Exclude mask background
plt.imshow(final_combined_mask, cmap=cmap, vmin=1)  # Adjust alpha for transparency

# Finalize the plot
plt.axis("off")
plt.tight_layout()
plt.savefig("/drive/MyDrive/BB_FULL_SLICE/FINALFINALFINAL.png", dpi=2000, bbox_inches='tight', pad_inches=0)

#plt.show()